## 哈希表

哈希表可以用来存储 key-value 的数据对，并且与之前树或者链表实现的 map 不同，哈希表能够以 O(1) 的复杂度进行数据的读写操作，这是因为哈希表的本质实际上是数组。

数组因为可以使用索引直接访问元素，并且由于内存地址连续，对 CPU 缓存也很友好，所以是所有数据结构中效率最高的。但是数组有两个明显的缺点：一是需要预先申请空间，后续扩容会有额外开销；二是只能用下标来高效访问元素，但是很多时候下标都是没有意义的。

像 Trie 中通过对字母进行 'a' 的偏移，让下标同时能够表示特定字母，从而让我们不需要显式维护字母一样，我们也可以通过某种方式，给数组的下标增加语义，或者说保证同样的内容每次都能得到确定的索引，我们就能够用数组存储任意内容，并且在常数时间内在数组中索引到对应的值。

这就是哈希表的核心原理：

通过 hash 函数将任意内容转化为数字，并通过模运算将该数字控制在一个较小的范围内，之后用该数字作为数组索引，将对应的内容存储在目标索引的位置上。

但是我们需要在数组范围内存储数据，所以需要确保数据的存储索引不要太大，否则内存的压力也会很大。但是可能存储的内容是无穷的，所以总有可能出现一组数据，无论用什么样的规则进行计算，都会计算出来一个相同的索引，这种情况就是**哈希冲突**或者**哈希碰撞**。

在出现冲突的时候，一般有两种方式来处理：

1. 在目标位置使用数组、链表或者树等结构进行存储，同样索引的位置可以存储多个值，就不怕冲突了（链地址法）；
2. 当遇到冲突的情况下，从冲突的位置的开始向后找空闲位置，来存储目标值（开放寻址法）。

综上所述，哈希表的本质就是数组，对目标 key 使用 hash 函数计算一个目标索引，在该位置进行数据的存储；如果遇到索引冲突的情况下，要么在每个 bucket 中使用其他容器来存储数据，要么通过某些方法寻找合适位置进行插入，从而保证把数据存储到数组中，之后就可以以 O(1) 的复杂度进行操作。

所以，对于哈希表来说，两部分内容比较重要：

- hash 函数的实现
    需要尽量保重不同内容的 hash 值是尽可能均匀的，要最大限度地避免冲突，从而保证哈希表的效率；
- 遇到冲突时的解决方式
    - 链地址法
    - 开放寻址法

接下来我们就对这两部分展开讨论一下。

### hash 函数

好的哈希函数应该能够将输入的数据均匀地映射到哈希表的各个位置，从而最大限度地减少冲突。

常见的哈希函数有：加法哈希、乘法哈希、

关于冲突，实际上存在两种层面的冲突：

- 哈希冲突：两个不同的输入得到相同的哈希值
- 索引冲突：两个不同的哈希值映射到相同的数组索引

哈希冲突和索引冲突实际上是两回事，哈希冲突一定索引冲突，但是索引冲突不一定哈希冲突。

因为输入空间通常是无限的，而哈希值空间是有限的（比如 32 位整数），即使数组长度无限大，仍然可能发生哈希冲突。

所以总结来说：
1. 哈希冲突是不可避免的（即使有无限内存）
2. 索引冲突是由于实际存储空间有限导致的
3. 好的哈希函数的目标是尽量减少哈希冲突
4. 好的索引映射方式的目标是尽量减少索引冲突

```c
int mul_hash(char* str) {
    int hash = 0;
    while (*str) {
        hash = hash * 31 + *str;
        str++;
    }
    return hash;
}

// 测试程序
int main() {
    char* str1 = "Aa";
    char* str2 = "BB";
    
    printf("hash(Aa) = %d\n", mul_hash(str1));
    printf("hash(BB) = %d\n", mul_hash(str2));
    
    return 0;
}
```

在乘法哈希（也叫 djb2 哈希）中，由于整数溢出的存在，确实可能出现哈希冲突。

这是一个著名的例子：字符串 "Aa" 和 "BB" 会产生相同的哈希值，因为：
"Aa": (0 31 + 65) 31 + 97 = 2112
"BB": (0 31 + 66) 31 + 66 = 2112
这种冲突与数组大小无关，纯粹是因为哈希算法本身的特性导致的。

```c
// 以下字符串对都会产生相同的哈希值
"dclq" 和 "cgrc"
"decj" 和 "cftc"
"dfbi" 和 "cgrb"

// 这些冲突是因为：
// 1. 整数溢出
// 2. 乘法和加法的分配律
// 3. ASCII 码值的特定组合
```

此外，链地址法使用链表而不是数组，主要还是因为数组需要预留空间。

如果使用数组来存储，即使桶里只有一个元素，也需要开 8 个元素的空间，在大部分时候用不上的情况下，有可能浪费 (2-6) 个元素类型空间 * 哈希表容量的内容空间。删除也是个问题，数组删除元素需要把元素向前移动，补上整个连续数组，但是链表只需要改变指针即可。

在实际实现中更倾向于使用链表：

1. 空间效率更高（按需分配）
2. 删除操作更高效（O(1) vs O(n)）
3. 当需要更好的查找性能时，可以平滑地转换为红黑树
4. 实现更简单，不需要处理数组的扩容问题

这种设计选择反映了实际应用中的典型场景：大多数哈希桶只包含很少的元素，而空间效率通常比缓存友好性更重要。

### hash 冲突

#### 链地址法



#### 开放寻址

在这种实现方式下，整个数组就是存储目标类型的值，每个桶里就装有目标值，如果遇到冲突就从当前位置向后去找第一个空的位置，然后执行插入。如果再插入新值，也有可能会和其他线性探测到某个位置插入的元素冲突，即下标 7 位置的元素原本的哈希值可能是 3，是和 3 冲突了才存到 7 来的，现在新插入一个本来就是 7 的值，但是因为 7 已经有值了，就也需要向后探测。所以线性探测的实现里，相当于是把每个桶里的值都拿出来摊开到数组里了。

假设哈希表大小为 10，使用简单的取模哈希函数：hash(key) = key % 10

1. 插入 13：
hash(13) = 3
[_, _, _, 13, _, _, _, _, _, _]

2. 插入 23：
hash(23) = 3，发生冲突，向后探测
[_, _, _, 13, 23, _, _, _, _, _]

3. 插入 24：
hash(24) = 4，位置 4 被占用，向后探测
[_, _, _, 13, 23, 24, _, _, _, _]

4. 插入 15：
hash(15) = 5，位置 5 被占用，向后探测
[_, _, _, 13, 23, 24, 15, _, _, _]

这个过程展示了几个重要特点：

1. 元素直接存储在数组中，没有额外的链表或树结构
2. 一个位置可能存储的是其他位置冲突后探测得到的元素
3. 查找时需要考虑探测序列：

```c
Value* find(HashTable* ht, Key key) {
    int index = hash(key);
    
    while (ht->array[index].status != EMPTY) {
        if (ht->array[index].status == OCCUPIED && 
            ht->array[index].key == key) {
            return &ht->array[index].value;
        }
        index = (index + 1) % ht->size;
    }
    return NULL;
}
```

删除操作尤其重要：

```c
// 不能直接置为空，否则会断开探测链
[_, _, _, 13, 23, 24, 15, _, _, _]
// 删除 23 后
[_, _, _, 13, D, 24, 15, _, _, _]  // D 表示删除标记
```

如果直接把 23 的位置置为空，那么在查找 15 时：

计算 hash(15) = 5，看到位置 5 是 24
继续探测，看到空位置
错误地认为 15 不存在
这就是为什么需要使用删除标记而不是直接清空位置的原因。

这种实现方式的特点：
空间利用率高（没有额外的指针开销）
2. 缓存友好（数据连续存储）
但是容易产生"聚集"现象（多个元素挤在一起）
装载因子不能太高（否则探测序列会很长）